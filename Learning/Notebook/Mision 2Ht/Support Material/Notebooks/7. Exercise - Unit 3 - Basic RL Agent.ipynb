{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxhqoMlfD0nTeDEO2ln/3S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# <FONT COLOR=\"red\">***REINFORCEMENT LEARNING (RL) AND DEEP RL AGENT***</FONT>\n","---\n","---\n","\n","To do so, it is important keep in mind that a RL or Deep RL Agent works rely on the OOP (Object-Oriented Programing), then to create a RL or Deep Rl agent is mandatory create an Agent and Environment class."],"metadata":{"id":"YDCppglMAHck"}},{"cell_type":"markdown","source":["## <FONT COLOR=\"orange\">**REINFORCEMENT LEARNING**</FONT>\n","---\n","---\n","\n","**R**einforcement **L**earning (**RL**) is a type of machine learning where an agent learns to interact with an environment by taking actions to maximize a reward. The agent learns through trial and error, receiving feedback in the form of rewards or penalties for its actions.\n","\n","Over time, the agent learns a policy, which is a strategy for selecting actions in different states to achieve its goal."],"metadata":{"id":"WX7yEBTLJjB5"}},{"cell_type":"code","source":["# IMPORT RANDOM LIBRARY\n","import random"],"metadata":{"id":"zfLmBuzpB0er","executionInfo":{"status":"ok","timestamp":1730503315819,"user_tz":300,"elapsed":225,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qBrIMjaV_s1R","executionInfo":{"status":"ok","timestamp":1730503174689,"user_tz":300,"elapsed":243,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"outputs":[],"source":["# AGENT CLASS DEFINITION\n","class RLAgent:\n","  # CONSTRUCTOR CLASS\n","  def __init__ (self, actions):\n","    self._actions = actions\n","  # SELECT ACTION METHOD\n","  def select_action(self, estado):\n","    return random.choice(self._actions)"]},{"cell_type":"code","source":["# ENVIRONMENT CLASS\n","class Environment:\n","  # CONSTRUCTOR CLASS\n","  def __init__ (self, states):\n","    self._states = states\n","  # TAKE ACTIONS\n","  def take_action(self, action):\n","    new_state = random.choice(self._states)\n","    reward = random.randint(0,100)\n","    return new_state, reward"],"metadata":{"id":"a7KKRZbvC7hY","executionInfo":{"status":"ok","timestamp":1730503613452,"user_tz":300,"elapsed":221,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# CREATE ACTIONS\n","posible_actions = ['left','rigth','up','down']\n","\n","# CREATE AGENT INSTANCE\n","agent = RLAgent(posible_actions)\n","\n","# CREATE ACTUAL STATE\n","actual_state = [0,0]"],"metadata":{"id":"MP3mt4bhBuSb","executionInfo":{"status":"ok","timestamp":1730503451189,"user_tz":300,"elapsed":194,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# TEST THE AGENT CLASS\n","action = agent.select_action(actual_state)\n","print(action)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xaf6tKkrCv3b","executionInfo":{"status":"ok","timestamp":1730503481350,"user_tz":300,"elapsed":212,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}},"outputId":"bc3216df-7129-4868-85bb-dce4bc08d1dc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["left\n"]}]},{"cell_type":"code","source":["# CREATE STATES\n","posible_states = ['A','B','C','D']\n","\n","# CREATE ENVIRONMENT INSTANCE\n","environment = Environment(posible_states)"],"metadata":{"id":"Eg68DU6rC5vD","executionInfo":{"status":"ok","timestamp":1730503648414,"user_tz":300,"elapsed":235,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# TEST THE ENVIRONMENT CLASS\n","action = agent.select_action(actual_state)\n","new_state, reward = environment.take_action(action)\n","print(f'New State: {new_state}. Reward: {reward}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tGIq_KWDiyl","executionInfo":{"status":"ok","timestamp":1730503724812,"user_tz":300,"elapsed":222,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}},"outputId":"e8b93b91-3e9f-4ea1-b918-d58292c52705"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["New State: C. Reward: 33\n"]}]},{"cell_type":"markdown","source":["## <FONT COLOR=\"orange\">**Q-LEARNING**</FONT>\n","---\n","---\n","\n","**Q-Learning** is a model-free reinforcement learning algorithm that learns the optimal policy by estimating the value of taking a specific action in a given state. This value is represented by a **Q-function**, denoted as $Q(s, a)$, where:\n","\n","*   $s$ represents the current state.\n","*   $a$ represents the action taken in that state.\n","\n"],"metadata":{"id":"s1re9jYgKz17"}},{"cell_type":"code","source":["# IMPORT RANDOM LIBRARY\n","import random"],"metadata":{"id":"NbMr57dSPCht","executionInfo":{"status":"ok","timestamp":1730506673997,"user_tz":300,"elapsed":5,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Q-LEARNING ENVIRONMENT CLASS\n","class QLearning:\n","  # CONSTRUCTION CLASS\n","  def __init__ (self, states, actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n","    self._states = states\n","    self._actions = actions\n","    self._alpha = alpha\n","    self._gamma = gamma\n","    self._epsilon = epsilon\n","    self._q_table = {}\n","\n","  # UPDATE Q-TABLE\n","  def update_q_table (self, actual_state, action, reward, new_state):\n","    # ADD A NEW STATE == ACTUAL STATE\n","    if actual_state not in self._q_table:\n","      self._q_table[actual_state] = {a: 0 for a in self._actions}\n","    # ADD A NEW STATE == NEW STATE\n","    if new_state not in self._q_table:\n","      self._q_table[new_state] = {a: 0 for a in self._actions}\n","    # SAVE Q-TABLE ACTUAL\n","    q_actual = self._q_table[actual_state][action]\n","    # MAX Q-VALUE\n","    max_q_value = max(self._q_table[new_state].values())\n","    # OBTAIN THE NEW Q-VALUE\n","    new_q_value = q_actual + self._alpha * (reward + self._gamma * max_q_value - q_actual)\n","    # UPDATE Q-VALUE\n","    self._q_table[actual_state][action] = new_q_value\n","\n","  # RETURN Q-TABLE\n","  def get_q_table (self):\n","    return self._q_table"],"metadata":{"id":"9L3_vdfJLiix","executionInfo":{"status":"ok","timestamp":1730506963665,"user_tz":300,"elapsed":197,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Q-LEARNING IMPLEMENTATION\n","states = ['A','B']\n","actions = ['left','rigth']\n","q_learning = QLearning(states, actions)"],"metadata":{"id":"TF2jPww8OhXf","executionInfo":{"status":"ok","timestamp":1730506996281,"user_tz":300,"elapsed":193,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# EPOCH SIMULATION\n","actual_state = random.choice(states)\n","action = random.choice(actions)\n","new_state = random.choice([state for state in states if state != actual_state])\n","reward = 10\n","q_learning.update_q_table(actual_state, action, reward, new_state)"],"metadata":{"id":"yV_daJHDOvFW","executionInfo":{"status":"ok","timestamp":1730507000252,"user_tz":300,"elapsed":206,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Q-TABLE VISUALIZATION\n","print('Update Q-Table:')\n","print(q_learning.get_q_table())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5jQCEHhP8pG","executionInfo":{"status":"ok","timestamp":1730507002257,"user_tz":300,"elapsed":218,"user":{"displayName":"EDWIN ANDRES SAMBONI ORTIZ","userId":"14774678352093959572"}},"outputId":"cdd4c5f7-1e7f-4998-d3b8-dc60f698f9d2"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Update Q-Table:\n","{'B': {'left': 1.0, 'rigth': 1.0}, 'A': {'left': 0, 'rigth': 1.09}}\n"]}]}]}